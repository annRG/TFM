{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation\n",
    "from keras.layers.core import Dense, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import categorical_crossentropy\n",
    "import tensorflow as tf\n",
    "\n",
    "import time\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import KFold# FUNCIONES GRAFICAS:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FUNCIONES  DE LAS GRAFICAS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history1(history):\n",
    "    hist = pd.DataFrame(history.history)\n",
    "    hist['epoch'] = history.epoch\n",
    "\n",
    "    plt.figure()\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Mean Abs Error [MPG]')\n",
    "    plt.plot(hist['epoch'], hist['mae'],\n",
    "           label='Train Error')\n",
    "    plt.plot(hist['epoch'], hist['val_mae'],\n",
    "           label = 'Val Error')\n",
    "    plt.ylim([0,plt.ylim()[1]])\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history2(history):\n",
    "    hist = pd.DataFrame(history.history)\n",
    "    hist['epoch'] = history.epoch\n",
    "\n",
    "    plt.figure()\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Mean Square Error [$MPG^2$]')\n",
    "    plt.plot(hist['epoch'], hist['mse'],\n",
    "           label='Train Error')\n",
    "    plt.plot(hist['epoch'], hist['val_mse'],\n",
    "           label = 'Val Error')\n",
    "    plt.ylim([0,plt.ylim()[1]])\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_comparacion(test_x,test_y):\n",
    "    plt.scatter( test_y , test_x )\n",
    "    plt.xlabel('True Values [MPG]')\n",
    "    plt.ylabel('Predictions [MPG]')\n",
    "    plt.axis('equal')\n",
    "    plt.axis('square')\n",
    "    plt.xlim([0,plt.xlim()[1]])\n",
    "    plt.ylim([0,plt.ylim()[1]])\n",
    "    _ = plt.plot(test_y , test_y , color = 'orange')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_histograma(test_x,test_y):\n",
    "    error = test_x - test_y\n",
    "    plt.hist(error, bins = 25)\n",
    "    plt.xlabel(\"Prediction Error [MPG]\")\n",
    "    _ = plt.ylabel(\"Count\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparacion de los datos NN simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_x2 = np.loadtxt('datos_x_2.txt')\n",
    "a_y2 = np.loadtxt('datos_y_2.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_m = x_data.reshape(( int(len(x_data)/(72)), 6 , 12 , 1 ))\n",
    "y_m = y_data.reshape(( int(len(y_data)/(72)), 6 , 12 , 1 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x_m\n",
    "y = y_m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definimos el metodo k-folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the K-fold Cross Validator\n",
    "num_folds = 4\n",
    "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
    "#Definir valores de numero de capas y numero de fold en el que estamos trabajando:\n",
    "fold_no = 1\n",
    "tipo = 'CONV2D_2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# K-fold Cross Validation model evaluation\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "\n",
    "for train, test in kfold.split(x, y):\n",
    "    \n",
    "    modelo = Sequential()\n",
    "    \n",
    "    modelo.add(Conv2D(72 , kernel_size=(1,1), activation='relu', input_shape = ((6,12,1))))\n",
    "\n",
    "    modelo.add(MaxPooling2D(pool_size=(2,2))) # layer to pool and reduce the dimensionality of the data.\n",
    "    modelo.add(Conv2D(30 , kernel_size=(1,1), activation='relu'))\n",
    "\n",
    "    #Comentar estas dos capas -----------------------------------------------------------------------------\n",
    "    modelo.add(MaxPooling2D(pool_size=(2, 2))) # layer to pool and reduce the dimensionality of the data.\n",
    "    modelo.add(Conv2D(15 , kernel_size=(1,1), activation='relu'))\n",
    "\n",
    "    modelo.add(UpSampling2D(size=( 3, 2))) # layer to pool and reduce the dimensionality of the data.\n",
    "    modelo.add(Conv2D(30 , kernel_size=(1,1), activation='relu'))\n",
    "    #------------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    modelo.add(UpSampling2D(size=( 2, 2))) # layer to pool and reduce the dimensionality of the data.\n",
    "    modelo.add(Conv2D(1 , kernel_size=(1,1), activation='relu'))\n",
    "\n",
    "\n",
    "    modelo.add(Flatten()) #Flatten the output from the convolutional layer and pass it to a Dense layer\n",
    "    modelo.add(Dense(72, activation='relu'))\n",
    "    modelo.add(Dense(30, activation='relu'))\n",
    "    modelo.add(Dense(15, activation='relu'))\n",
    "    modelo.add(Dense(30, activation='relu'))\n",
    "    modelo.add(Dense(72))\n",
    "    modelo.summary()\n",
    "\n",
    "    # COMPILACION DEL MODELO\n",
    "    optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
    "\n",
    "    modelo.compile(loss='mse',\n",
    "                optimizer=optimizer,\n",
    "                metrics=['mae', 'mse'])\n",
    "\n",
    "\n",
    "    \n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Training for fold {fold_no} ...')\n",
    "\n",
    "    # ENTRENAMIENTO DE LOS DATOS:\n",
    "    \n",
    "    x_train_1 = x[train][:int(len(x[train])/4 * 3)]\n",
    "    x_val = x[train][int(len(x[train])/4 * 3):]\n",
    "    y_train_1 = y[train][:int(len(y[train])/4 * 3)]\n",
    "    y_val = y[train][int(len(y[train])/4 * 3):]\n",
    "    \n",
    "\n",
    "    \n",
    "    history = modelo.fit(x_train_1, y_train_1,\n",
    "                         validation_data=(x_val, y_val),\n",
    "                         batch_size=1,\n",
    "                         epochs=100,\n",
    "                         verbose=0)\n",
    "    \n",
    "    #GRAFICAS DEL PRIMER ENTRENAMIENTO:\n",
    "    hist = pd.DataFrame(history.history)\n",
    "    hist['epoch'] = history.epoch\n",
    "    hist.to_csv('Hist_' + str(fold_no) + '_' + str(tipo) + '.csv')\n",
    "    \n",
    "    plot_history1(history)\n",
    "    time.sleep(10) \n",
    "    \n",
    "    plot_history2(history)\n",
    "    time.sleep(10) \n",
    "    \n",
    "\n",
    "    # ENTRENAMIENTO DEL MODELO DE SEGUNDA VEZ \n",
    "    print('    ')\n",
    "    print('Segundo entrenamiento del modelo')\n",
    "    print('    ')\n",
    "    a = modelo.fit(x[train], y[train],\n",
    "                   batch_size=1,\n",
    "                   epochs=100,\n",
    "                   verbose=0)\n",
    "\n",
    "    hist2 = pd.DataFrame(a.history)\n",
    "    hist2['epoch'] = a.epoch\n",
    "    \n",
    "    \n",
    "    # EVALUAMOS EL MODELO\n",
    "    scores = modelo.evaluate(x[test], y[test], verbose=0)\n",
    "    print('    ')\n",
    "    print('    ')\n",
    "    print('    ')\n",
    "    print(f'Score for fold {fold_no}: {modelo.metrics_names[0]} of {scores[0]}; {modelo.metrics_names[1]} of {scores[1]}')\n",
    "    acc_per_fold.append(scores[1] * 100)\n",
    "    loss_per_fold.append(scores[0])\n",
    "    \n",
    "    #REALIZAMOS LAS PREDICCIONES:\n",
    "    test_x = modelo.predict(x[test])\n",
    "    test_y = y[test]\n",
    "    \n",
    "    #MOSTRAMOS UNA DE LA SPREDICCIONES PARA COMPARAR REAL-PREDICCION:\n",
    "    print('Prediccion: ')\n",
    "    print(test_x[1])\n",
    "    print('Real: ')\n",
    "    print(test_y[1])\n",
    "    \n",
    "    #GRAFICAS DEL SEGUNDO ENTRENAMIENTO:\n",
    "    plot_comparacion(test_x, test_y)\n",
    "    \n",
    "    plot_histograma(test_x,test_y)\n",
    "    \n",
    "    print('    ')\n",
    "    print('    ')\n",
    "    print('    ')\n",
    "    print('Terminamos hoja numero --------------------------------------------------> ' , fold_no )\n",
    "    print('    ')\n",
    "    print('    ')\n",
    "    print('    ')\n",
    "    \n",
    "    # INCREMENTAMOS EL NUMERO DE HOJAS:\n",
    "    \n",
    "    fold_no = fold_no + 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
